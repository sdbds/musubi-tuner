# UI Text Dictionary for potential i18n
# I18N Configuration
I18N_DATA = {
    "en": {
        "app_title": "Musubi Tuner GUI",
        "app_header": "# Musubi Tuner GUI",
        "app_desc": "A simple frontend for training LoRA models with Musubi Tuner.",
        "acc_project": "1. Project Settings",
        "desc_project": "All working files will be created under this directory.",
        "lbl_proj_dir": "Project Working Directory",
        "ph_proj_dir": "Absolute path to your project folder",
        "btn_init_project": "Initialize/Load Project",
        "acc_model": "2. Model & Dataset Configuration",
        "desc_model": "Choose the model architecture and specify the ComfyUI models directory.",
        "lbl_model_arch": "Model Architecture",
        "lbl_vram": "VRAM Size (GB)",
        "lbl_comfy_dir": "ComfyUI Models Directory",
        "ph_comfy_dir": "Absolute path to ComfyUI/models",
        "btn_validate_models": "Validate Models Directory",
        "header_dataset": "### 3. Dataset Settings",
        "desc_dataset": "Configure the resolution and batch size for the dataset. Regenerate the dataset config if you change resolution or batch size.",
        "btn_rec_res_batch": "Set Recommended Resolution & Batch Size",
        "lbl_res_w": "Resolution Width",
        "lbl_res_h": "Resolution Height",
        "lbl_batch_size": "Batch Size",
        "btn_gen_config": "Generate Dataset Config",
        "lbl_toml_preview": "TOML Preview",
        "acc_preprocessing": "4. Preprocessing",
        "desc_preprocessing": "Pre-calculate latents and text encoder outputs required for training.",
        "btn_set_paths": "Set Default Paths",
        "lbl_vae_path": "VAE Path",
        "ph_vae_path": "Path to VAE model",
        "lbl_te1_path": "Text Encoder 1 Path",
        "ph_te1_path": "Path to Text Encoder 1",
        "lbl_te2_path": "Text Encoder 2 Path",
        "ph_te2_path": "Path to Text Encoder 2 (Optional)",
        "btn_cache_latents": "Cache Latents",
        "btn_cache_text": "Cache Text Encoder Outputs",
        "lbl_cache_log": "Caching Log Output",
        "acc_training": "5. Training",
        "desc_training_basic": "Configure the training parameters. If you train with the same name again, the previous LoRA will be overwritten.",
        "desc_training_zimage": "Recommended: Use **bf16** for mixed precision. Because the base model has not been released yet, please use `z_image_de_turbo_v1_bf16.safetensors` as the base model.",
        "btn_rec_params": "Set Recommended Parameters",
        "lbl_dit_path": "Base Model / DiT Path",
        "ph_dit_path": "Path to DiT model",
        "lbl_output_name": "Output LoRA Name",
        "header_basic_params": "### Basic Parameters",
        "lbl_dim": "LoRA Rank (Dim)",
        "lbl_lr": "Learning Rate",
        "lbl_epochs": "Epochs",
        "lbl_save_every": "Save Every N Epochs",
        "accordion_advanced": "Advanced Parameters",
        "desc_training_detailed": """
### Detailed Explanation
- **Learning Rate**: Controls how much the model weights are updated during training. Lower values are safer but slower.
- **Epochs**: One complete pass through the entire training dataset.
- **Save Every N Epochs**: How often to save the model and generate sample images.
- **Discrete Flow Shift**: A parameter specific to flow matching models.
- **Block Swap**: Offloads model blocks to CPU to save VRAM. Higher values save more VRAM but slow down training.
- **Mixed Precision**: fp16 and bf16 are both supported; which is better depends on the model architecture. For bf16, RTX30xx or higher is required.
- **Gradient Checkpointing**: Saves VRAM by recomputing activations during backward pass.
- **FP8**: Further reduces memory usage by using 8-bit floating point arithmetic.
""",
        "lbl_flow_shift": "Discrete Flow Shift",
        "lbl_block_swap": "Block Swap (0-28)",
        "lbl_mixed_precision": "Mixed Precision",
        "lbl_grad_cp": "Gradient Checkpointing",
        "lbl_fp8_scaled": "FP8 Scaled (DiT) - Enables --fp8_base and --fp8_scaled",
        "lbl_fp8_llm": "FP8 LLM/VLM (Text Encoder)",
        "header_sample_images": "### Sample Image Generation",
        "lbl_enable_sample": "Generate Sample Images During Training",
        "lbl_sample_every_n": "Generate Sample Every N Epochs",
        "lbl_sample_prompt": "Sample Prompt",
        "ph_sample_prompt": "Prompt for sample generation",
        "lbl_sample_negative_prompt": "Sample Negative Prompt",
        "ph_sample_negative_prompt": "Negative prompt for sample generation",
        "lbl_sample_w": "Sample Width",
        "lbl_sample_h": "Sample Height",
        "accordion_additional": "Additional Options",
        "desc_additional_args": "Enter any additional command line arguments here. They will be appended to the training command.",
        "lbl_additional_args": "Additional Optional Arguments",
        "ph_additional_args": "--arg value --flag",
        "btn_start_training": "Start Training (New Window)",
        "acc_post_processing": "6. Post-Processing",
        "desc_post_proc": "Convert Z-Image LoRA to ComfyUI format.",
        "lbl_input_lora": "Input LoRA Path",
        "ph_input_lora": "Path to trained .safetensors file",
        "lbl_output_comfy": "Output ComfyUI LoRA Path",
        "ph_output_comfy": "Path to save converted model",
        "btn_convert": "Convert to ComfyUI Format",
        "lbl_conversion_log": "Conversion Log",
        "desc_qwen_notes": "Qwen-Image specific notes here.",
    },
    "ja": {
        "app_title": "Musubi Tuner GUI",
        "app_header": "# Musubi Tuner GUI",
        "app_desc": "Musubi TunerでLoRAモデルを学習するためのシンプルなフロントエンドです。",
        "acc_project": "1. プロジェクト設定",
        "desc_project": "すべての作業ファイルはこのディレクトリ下に作成されます。",
        "lbl_proj_dir": "プロジェクト作業ディレクトリ",
        "ph_proj_dir": "プロジェクトフォルダへの絶対パス",
        "btn_init_project": "プロジェクトを初期化/読み込み",
        "acc_model": "2. モデル＆データセット設定",
        "desc_model": "モデルアーキテクチャを選択し、ComfyUIのモデルディレクトリを指定してください。",
        "lbl_model_arch": "モデルアーキテクチャ",
        "lbl_vram": "VRAMサイズ (GB)",
        "lbl_comfy_dir": "ComfyUI モデルディレクトリ",
        "ph_comfy_dir": "ComfyUI/models への絶対パス",
        "btn_validate_models": "モデルディレクトリを検証",
        "header_dataset": "### 3. データセット設定",
        "desc_dataset": "データセットの解像度とバッチサイズを設定してください。解像度やバッチサイズを変えた場合は、データセット設定を再生成してください。",
        "btn_rec_res_batch": "推奨解像度とバッチサイズを設定",
        "lbl_res_w": "解像度 幅",
        "lbl_res_h": "解像度 高さ",
        "lbl_batch_size": "バッチサイズ",
        "btn_gen_config": "データセット設定(TOML)を生成",
        "lbl_toml_preview": "TOML プレビュー",
        "acc_preprocessing": "4. 前処理 (Preprocessing)",
        "desc_preprocessing": "学習に必要となるLatentsとテキストエンコーダーの出力を事前計算します。",
        "btn_set_paths": "デフォルトパスを設定",
        "lbl_vae_path": "VAE パス",
        "ph_vae_path": "VAEモデルへのパス",
        "lbl_te1_path": "テキストエンコーダー1 パス",
        "ph_te1_path": "テキストエンコーダー1へのパス",
        "lbl_te2_path": "テキストエンコーダー2 パス",
        "ph_te2_path": "テキストエンコーダー2へのパス (オプション)",
        "btn_cache_latents": "Latentsをキャッシュ",
        "btn_cache_text": "テキストエンコーダー出力をキャッシュ",
        "lbl_cache_log": "キャッシュログ出力",
        "acc_training": "5. 学習 (Training)",
        "desc_training_basic": "学習パラメータを設定してください。学習後、同じ名前で学習すると前のLoRAが上書きされます。",
        "desc_training_zimage": "推奨: 混合精度には **bf16** を使用してください。Baseモデルがリリースされていないため、ostris氏の `z_image_de_turbo_v1_bf16.safetensors` を使用してください。",
        "btn_rec_params": "推奨パラメータを設定",
        "lbl_dit_path": "ベースモデル / DiT パス",
        "ph_dit_path": "DiTモデルへのパス",
        "lbl_output_name": "出力 LoRA 名",
        "header_basic_params": "### 基本パラメータ",
        "lbl_dim": "LoRAランク (Dim)",
        "lbl_lr": "学習率 (Learning Rate)",
        "lbl_epochs": "エポック数 (Epochs)",
        "lbl_save_every": "Nエポックごとに保存",
        "accordion_advanced": "詳細パラメータ",
        "desc_training_detailed": """
### 詳細説明
- **学習率 (Learning Rate)**: 学習中にモデルの重みをどれくらい更新するかを制御します。低い値の方が安全ですが、学習が遅くなります。
- **エポック数 (Epochs)**: 学習データセット全体を通す回数です。
- **保存頻度 (Save Every N Epochs)**: モデルの保存とサンプル生成を行う頻度です。
- **Discrete Flow Shift**: Flow Matchingモデル特有のパラメータです。
- **Block Swap**: VRAMを節約するためにモデルブロックをCPUにオフロードします。値を大きくするとVRAMを節約できますが、学習が遅くなります。
- **混合精度 (Mixed Precision)**: モデルアーキテクチャによりfp16とbf16のどちらが適しているかは異なります。bf16はRTX30xx以降のGPUが必要です。
- **Gradient Checkpointing**: Backwardパス中にアクティベーションを再計算することでVRAMを節約します。
- **FP8**: 8ビット浮動小数点演算を使用することでメモリ使用量をさらに削減します。
""",
        "lbl_flow_shift": "Discrete Flow Shift",
        "lbl_block_swap": "Block Swap (0-28)",
        "lbl_mixed_precision": "混合精度 (Mixed Precision)",
        "lbl_grad_cp": "Gradient Checkpointing",
        "lbl_fp8_scaled": "FP8 Scaled (DiT) - --fp8_base と --fp8_scaled を有効化",
        "lbl_fp8_llm": "FP8 LLM/VLM (テキストエンコーダー)",
        "header_sample_images": "### サンプル画像生成",
        "lbl_enable_sample": "学習中にサンプル画像を生成する",
        "lbl_sample_every_n": "Nエポックごとにサンプルを生成",
        "lbl_sample_prompt": "サンプル画像プロンプト",
        "ph_sample_prompt": "サンプル生成用のプロンプト",
        "lbl_sample_negative_prompt": "サンプル画像ネガティブプロンプト",
        "ph_sample_negative_prompt": "サンプル生成用のネガティブプロンプト",
        "lbl_sample_w": "サンプル画像 幅",
        "lbl_sample_h": "サンプル画像 高さ",
        "accordion_additional": "追加オプション",
        "desc_additional_args": "追加のコマンドライン引数を入力してください。これらは学習コマンドに追加されます。",
        "lbl_additional_args": "追加のオプション引数",
        "ph_additional_args": "--arg value --flag",
        "btn_start_training": "学習を開始 (新しいウィンドウが開きます)",
        "acc_post_processing": "6. 後処理 (Post-Processing)",
        "desc_post_proc": "Z-Image LoRAをComfyUI形式に変換します。",
        "lbl_input_lora": "入力 LoRA パス",
        "ph_input_lora": "学習済み .safetensors ファイルへのパス",
        "lbl_output_comfy": "出力 ComfyUI LoRA パス",
        "ph_output_comfy": "変換後のモデルの保存先パス",
        "btn_convert": "ComfyUI形式に変換",
        "lbl_conversion_log": "変換ログ",
        "desc_qwen_notes": "Qwen-Image 特有の注意点。",
    },
}
